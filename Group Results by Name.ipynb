{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Results by Name\n",
    "\n",
    "> This notebook merges the CSV files containing photon and burst data \n",
    "> for the repeats of each sample.\n",
    ">\n",
    "> Before running this notebook, \n",
    "> you should run the notebook [Batch run notebook](Batch run notebook.ipynb) \n",
    "> to execute the burst search on each individual file and to export \n",
    "> the CSV files for photon and burst data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the data files\n",
    "\n",
    "Folder of Photon-HDF5 files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path('../Relevant BH measurements/lacCONS Cy3B Atto647N RNAP/photonHDF5/minus8TA_minus5NTD/') \n",
    "assert data_folder.is_dir(), f'Folder not found: \"{str(data_folder)}\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folder of CSV files containing burst data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../Relevant BH measurements/lacCONS Cy3B Atto647N RNAP/photonHDF5/results/minus8TA_minus5NTD')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folder of the CSV files\n",
    "results_folder = data_folder.parent\n",
    "results_folder = results_folder.parent\n",
    "results_folder = data_folder.parent / 'results' / 'minus8TA_minus5NTD'\n",
    "results_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect filenames of Photon-HDF5 files with matching CSV files (to generate the CSV files you need to run the burst search for each file using the \"Batch\" notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fret_suffix = '_FRET_bursts'\n",
    "donly_suffix = '_Donly_bursts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of HDF5 files corresponding to existing CSV files\n",
    "filelist = [Path(f.parents[1], 'photonHDF5', f.stem[:-len(fret_suffix)] + '.hdf5') \n",
    "            for f in results_folder.glob(f'*{fret_suffix}.csv') if 'merge' not in f.name]\n",
    "[f.name for f in filelist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a table of files. The index will be the file name, the column \"name\" is a label used to identify the sample and \"repeat\" is the repeat number for each sample.\n",
    "We also add a few more columns that will be filled later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(\n",
    "    columns=['fname', 'name', 'repeat', 'num_bursts_fret', 'num_bursts_donly', \n",
    "             'size', 'duration'],\n",
    "    index=range(len(filelist)))\n",
    "df_all.fname = [f.stem for f in filelist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customize below if you want to extract a sample \"name\" \n",
    "according to a different pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>repeat</th>\n",
       "      <th>num_bursts_fret</th>\n",
       "      <th>num_bursts_donly</th>\n",
       "      <th>size</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dsdna_d17_1</th>\n",
       "      <td>d17</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d17_2</th>\n",
       "      <td>d17</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d17_3</th>\n",
       "      <td>d17</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d7+d17_50_50_1</th>\n",
       "      <td>d7+d17</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d7+d17_50_50_2</th>\n",
       "      <td>d7+d17</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d7+d17_50_50_3</th>\n",
       "      <td>d7+d17</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d7_1</th>\n",
       "      <td>d7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d7_2</th>\n",
       "      <td>d7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d7_3</th>\n",
       "      <td>d7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  repeat num_bursts_fret num_bursts_donly size  \\\n",
       "fname                                                                        \n",
       "dsdna_d17_1              d17       1             NaN              NaN  NaN   \n",
       "dsdna_d17_2              d17       2             NaN              NaN  NaN   \n",
       "dsdna_d17_3              d17       3             NaN              NaN  NaN   \n",
       "dsdna_d7+d17_50_50_1  d7+d17       1             NaN              NaN  NaN   \n",
       "dsdna_d7+d17_50_50_2  d7+d17       2             NaN              NaN  NaN   \n",
       "dsdna_d7+d17_50_50_3  d7+d17       3             NaN              NaN  NaN   \n",
       "dsdna_d7_1                d7       1             NaN              NaN  NaN   \n",
       "dsdna_d7_2                d7       2             NaN              NaN  NaN   \n",
       "dsdna_d7_3                d7       3             NaN              NaN  NaN   \n",
       "\n",
       "                     duration  \n",
       "fname                          \n",
       "dsdna_d17_1               NaN  \n",
       "dsdna_d17_2               NaN  \n",
       "dsdna_d17_3               NaN  \n",
       "dsdna_d7+d17_50_50_1      NaN  \n",
       "dsdna_d7+d17_50_50_2      NaN  \n",
       "dsdna_d7+d17_50_50_3      NaN  \n",
       "dsdna_d7_1                NaN  \n",
       "dsdna_d7_2                NaN  \n",
       "dsdna_d7_3                NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.name = (df_all.fname\n",
    "                .str.replace('minus8ta_minus5ntd_', '')\n",
    "df_all.repeat = df_all.fname.str.split('_').str.get(-1).astype('int')\n",
    "df_all = df_all.set_index('fname')\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fill all the other columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>repeat</th>\n",
       "      <th>num_bursts_fret</th>\n",
       "      <th>num_bursts_donly</th>\n",
       "      <th>size</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dsdna_d17_1</th>\n",
       "      <td>d17</td>\n",
       "      <td>1</td>\n",
       "      <td>1689</td>\n",
       "      <td>2234</td>\n",
       "      <td>14.3285</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d17_2</th>\n",
       "      <td>d17</td>\n",
       "      <td>2</td>\n",
       "      <td>1419</td>\n",
       "      <td>2190</td>\n",
       "      <td>12.9113</td>\n",
       "      <td>1245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d17_3</th>\n",
       "      <td>d17</td>\n",
       "      <td>3</td>\n",
       "      <td>509</td>\n",
       "      <td>767</td>\n",
       "      <td>4.71971</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d7+d17_50_50_1</th>\n",
       "      <td>d7+d17</td>\n",
       "      <td>1</td>\n",
       "      <td>5981</td>\n",
       "      <td>6062</td>\n",
       "      <td>34.6641</td>\n",
       "      <td>1885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d7+d17_50_50_2</th>\n",
       "      <td>d7+d17</td>\n",
       "      <td>2</td>\n",
       "      <td>4772</td>\n",
       "      <td>5967</td>\n",
       "      <td>29.8074</td>\n",
       "      <td>1590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d7+d17_50_50_3</th>\n",
       "      <td>d7+d17</td>\n",
       "      <td>3</td>\n",
       "      <td>4218</td>\n",
       "      <td>6386</td>\n",
       "      <td>29.4961</td>\n",
       "      <td>1555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d7_1</th>\n",
       "      <td>d7</td>\n",
       "      <td>1</td>\n",
       "      <td>575</td>\n",
       "      <td>2807</td>\n",
       "      <td>11.4511</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d7_2</th>\n",
       "      <td>d7</td>\n",
       "      <td>2</td>\n",
       "      <td>585</td>\n",
       "      <td>3162</td>\n",
       "      <td>12.7444</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdna_d7_3</th>\n",
       "      <td>d7</td>\n",
       "      <td>3</td>\n",
       "      <td>322</td>\n",
       "      <td>1875</td>\n",
       "      <td>7.50941</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  repeat  num_bursts_fret  num_bursts_donly  \\\n",
       "fname                                                                     \n",
       "dsdna_d17_1              d17       1             1689              2234   \n",
       "dsdna_d17_2              d17       2             1419              2190   \n",
       "dsdna_d17_3              d17       3              509               767   \n",
       "dsdna_d7+d17_50_50_1  d7+d17       1             5981              6062   \n",
       "dsdna_d7+d17_50_50_2  d7+d17       2             4772              5967   \n",
       "dsdna_d7+d17_50_50_3  d7+d17       3             4218              6386   \n",
       "dsdna_d7_1                d7       1              575              2807   \n",
       "dsdna_d7_2                d7       2              585              3162   \n",
       "dsdna_d7_3                d7       3              322              1875   \n",
       "\n",
       "                         size  duration  \n",
       "fname                                    \n",
       "dsdna_d17_1           14.3285      1368  \n",
       "dsdna_d17_2           12.9113      1245  \n",
       "dsdna_d17_3           4.71971       444  \n",
       "dsdna_d7+d17_50_50_1  34.6641      1885  \n",
       "dsdna_d7+d17_50_50_2  29.8074      1590  \n",
       "dsdna_d7+d17_50_50_3  29.4961      1555  \n",
       "dsdna_d7_1            11.4511       788  \n",
       "dsdna_d7_2            12.7444       879  \n",
       "dsdna_d7_3            7.50941       511  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for f in filelist[::-1]:\n",
    "    df_all.loc[f.stem, 'size'] = f.stat().st_size / 1024 / 1024\n",
    "    \n",
    "    burst_fname = Path(results_folder, f.stem + f'{fret_suffix}.csv')\n",
    "    dx = pd.read_csv(burst_fname, index_col=0)\n",
    "    df_all.loc[f.stem, 'num_bursts_fret'] = dx.shape[0]\n",
    "    duration = np.round(dx.t_start.iloc[-1] - dx.t_start.iloc[0])\n",
    "    df_all.loc[f.stem, 'duration'] = duration\n",
    "    \n",
    "    burst_fname = Path(results_folder, f.stem + f'{donly_suffix}.csv')\n",
    "    dx = pd.read_csv(burst_fname, index_col=0)\n",
    "    df_all.loc[f.stem, 'num_bursts_donly'] = dx.shape[0]\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate photon data\n",
    "\n",
    "All measurements with same \"name\" will be merged in a single file.\n",
    "\n",
    "We start merging the photon data (timestamps, nanotimes etc..):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fret_suffixp = '_FRET_burst_photons'\n",
    "donly_suffixp = '_Donly_burst_photons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_by_concentration(suffix, df_all):\n",
    "    # `burstph_dict1`: key is concentration, values lists of DataFrame\n",
    "    burstph_dict1 = defaultdict(list)\n",
    "    for (name, repeat), df_c in df_all.groupby(['name', 'repeat']):\n",
    "        for fname, s in df_c.iterrows():\n",
    "            burstph_fname = Path(results_folder, fname + f'{suffix}.csv')\n",
    "            header = burstph_fname.read_text().split('\\n')[0]\n",
    "            meta = json.loads(header)\n",
    "            df_all.loc[fname, 'donly_lifetime'] = meta['donly_lifetime']\n",
    "            df_all.loc[fname, 'timestamp_unit'] = meta['timestamp_unit']\n",
    "            df_all.loc[fname, 'nanotime_unit'] = meta['nanotime_unit']\n",
    "            dx = pd.read_csv(burstph_fname, skiprows=1, index_col=(0, 1))\n",
    "            assert (np.diff(dx.timestamp) >= 0).all()\n",
    "            dx['repeat'] = np.uint8(repeat)\n",
    "            burstph_dict1[name].append(dx)\n",
    "    assert np.allclose(df_all.timestamp_unit, df_all.timestamp_unit.mean())\n",
    "    assert np.allclose(df_all.nanotime_unit, df_all.nanotime_unit.mean())\n",
    "\n",
    "    # `burstph_dict`: like `burstph_dict1` but with unique burst ids at a given concentration\n",
    "    burstph_dict = defaultdict(list)\n",
    "    for name, burstph_list in burstph_dict1.items():\n",
    "        df_list2 = []\n",
    "        burst_offset = 0\n",
    "        ts_offset = 0\n",
    "        for i, df in enumerate(burstph_list):\n",
    "            df2 = df.reset_index('burst')\n",
    "            num_bursts = len(df2.burst.unique())\n",
    "            df2.burst += burst_offset\n",
    "            burst_offset += num_bursts\n",
    "            df2.timestamp += ts_offset\n",
    "            ts_offset += df2.timestamp.values[-1]\n",
    "            burstph_dict[name].append(\n",
    "                df2.set_index('burst', append=True)\n",
    "                   .reorder_levels(['burst', 'ph']))    \n",
    "\n",
    "    # Test consistency of burstph_dict and burstph_dict1\n",
    "    for name, burstph_list in burstph_dict.items():\n",
    "        burstph_list1 = burstph_dict1[name]\n",
    "        prev_burst = -1\n",
    "        for df1, df2 in zip(burstph_list1, burstph_list):\n",
    "            df1 = df1.reset_index()\n",
    "            df2 = df2.reset_index()\n",
    "            assert df2.burst.iloc[0] == df2.burst.min()\n",
    "            assert df2.burst.iloc[-1] == df2.burst.max()\n",
    "            assert (np.diff(df2.burst.unique()) == 1).all()\n",
    "            assert df2.burst.iloc[0] == prev_burst + 1\n",
    "            prev_burst = df2.burst.iloc[-1]\n",
    "\n",
    "            assert (df1.burst == df2.burst - df2.burst.min()).all()\n",
    "            for c in df1.columns:\n",
    "                if c == 'burst': break\n",
    "                assert (df1[c] == df2[c]).all()\n",
    "\n",
    "    # Create a dict of DataFrame merging by concentration\n",
    "    burstph_dict_merge = {n: pd.concat(df_list) \n",
    "                          for n, df_list in burstph_dict.items()}\n",
    "\n",
    "    # Test consistency of `burstph_dict_merge` and `burstph_dict`\n",
    "    for n, df in burstph_dict_merge.items():\n",
    "        assert df.shape[0] == sum([x.shape[0] for x in burstph_dict[n]])\n",
    "        num_bursts = len(df.reset_index().burst.unique())\n",
    "        assert num_bursts == sum([len(x.reset_index().burst.unique())\n",
    "                                 for x in burstph_dict[n]])\n",
    "        df2 = df.copy().reset_index()\n",
    "        assert df2.burst.iloc[0] == df2.burst.min()\n",
    "        assert df2.burst.iloc[-1] == df2.burst.max()\n",
    "        assert (np.diff(df2.burst.unique()) == 1).all()\n",
    "    return burstph_dict_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge photon data FRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FRET'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix = fret_suffixp\n",
    "suffix.split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "burstph_dict_merge = merge_by_concentration(suffix, df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save photon data FRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>donly_lifetime</th>\n",
       "      <th>timestamp_unit</th>\n",
       "      <th>nanotime_unit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d17</th>\n",
       "      <td>3.905157</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>1.467823e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d7+d17</th>\n",
       "      <td>3.939998</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>1.467823e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d7</th>\n",
       "      <td>3.992275</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>1.467823e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        donly_lifetime  timestamp_unit  nanotime_unit\n",
       "name                                                 \n",
       "d17           3.905157    5.000000e-08   1.467823e-11\n",
       "d7+d17        3.939998    5.000000e-08   1.467823e-11\n",
       "d7            3.992275    5.000000e-08   1.467823e-11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = pd.DataFrame(index=df_all.name.unique())\n",
    "df_merge.index.name = 'name'\n",
    "df_merge['donly_lifetime'] = df_all.groupby('name')['donly_lifetime'].mean()\n",
    "df_merge['timestamp_unit'] = np.round(df_all.groupby('name')['timestamp_unit'].mean(), 9)\n",
    "df_merge['nanotime_unit'] = df_all.groupby('name')['nanotime_unit'].mean()\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name d17: (array([], dtype=int64),)\n",
      "Name d7+d17: (array([], dtype=int64),)\n",
      "Name d7: (array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "for name in df_merge.index:\n",
    "    print(f'Name {name}:', np.where(burstph_dict_merge[name].timestamp.diff() < 0))\n",
    "    assert (burstph_dict_merge[name].timestamp.diff()[1:] >= 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Saving file \"d17_merge_FRET_burst_photons.csv\"\n",
      " - Saving file \"d7+d17_merge_FRET_burst_photons.csv\"\n",
      " - Saving file \"d7_merge_FRET_burst_photons.csv\"\n"
     ]
    }
   ],
   "source": [
    "for name, row in df_merge.iterrows():\n",
    "    burstph_fname = Path(results_folder, name + f'_merge{suffix}.csv')\n",
    "    print(f' - Saving file \"{burstph_fname.name}\"')\n",
    "    meta = dict(\n",
    "        description=f\"Merged photon data for {suffix.split('_')[1]} bursts for '{name}' measurement.\",\n",
    "        timestamp_unit=row.timestamp_unit,\n",
    "        nanotime_unit=row.nanotime_unit,\n",
    "        donly_lifetime=row.donly_lifetime)\n",
    "    \n",
    "    with open(burstph_fname, mode='wt') as f:\n",
    "        json.dump(meta, f)\n",
    "        f.write('\\n')\n",
    "        burstph_dict_merge[name].to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge photon data D-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Donly'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix = donly_suffixp\n",
    "suffix.split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_Donly_burst_photons'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "burstph_dict_mergeD = merge_by_concentration(suffix, df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save photon data D-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Saving file \"d17_merge_Donly_burst_photons.csv\"\n",
      " - Saving file \"d7+d17_merge_Donly_burst_photons.csv\"\n",
      " - Saving file \"d7_merge_Donly_burst_photons.csv\"\n"
     ]
    }
   ],
   "source": [
    "for name, row in df_merge.iterrows():\n",
    "    burstph_fname = Path(results_folder, name + f'_merge{suffix}.csv')\n",
    "    print(f' - Saving file \"{burstph_fname.name}\"')\n",
    "    meta = dict(\n",
    "        description=f\"Merged photon data for {suffix.split('_')[1]} bursts for '{name}' measurement.\",\n",
    "        timestamp_unit=row.timestamp_unit,\n",
    "        nanotime_unit=row.nanotime_unit,\n",
    "        donly_lifetime=row.donly_lifetime)\n",
    "    \n",
    "    with open(burstph_fname, mode='wt') as f:\n",
    "        json.dump(meta, f)\n",
    "        f.write('\\n')\n",
    "        burstph_dict_mergeD[name].to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the photon data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the photon data for all the concentrations\n",
    "using only a variable `folder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_FRET_burst_photons'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix = fret_suffixp\n",
    "suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading ../Relevant BH measurements/dsDNA/results/d17_merge_FRET_burst_photons.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/miniconda3/envs/py36-sys/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading ../Relevant BH measurements/dsDNA/results/d7+d17_merge_FRET_burst_photons.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/miniconda3/envs/py36-sys/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading ../Relevant BH measurements/dsDNA/results/d7_merge_FRET_burst_photons.csv\n"
     ]
    }
   ],
   "source": [
    "burstph_dict_merge2 = {}\n",
    "for fname in Path(results_folder).glob(f'*_merge{suffix}.csv'):\n",
    "    print(f'- Loading {fname}')\n",
    "    name = fname.stem.split('_')[0]\n",
    "    burstph_dict_merge2[name] = pd.read_csv(fname, skiprows=1, index_col=(0, 1))\n",
    "    header = fname.read_text().split('\\n')[0]\n",
    "    burstph_dict_merge2[name].meta = json.loads(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test roundtrip\n",
    "for name in burstph_dict_merge:\n",
    "    assert (burstph_dict_merge[name] == burstph_dict_merge2[name]).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_Donly_burst_photons'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix = donly_suffixp\n",
    "suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading ../Relevant BH measurements/dsDNA/results/d17_merge_Donly_burst_photons.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/miniconda3/envs/py36-sys/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading ../Relevant BH measurements/dsDNA/results/d7+d17_merge_Donly_burst_photons.csv\n",
      "- Loading ../Relevant BH measurements/dsDNA/results/d7_merge_Donly_burst_photons.csv\n"
     ]
    }
   ],
   "source": [
    "burstph_dict_mergeD2 = {}\n",
    "for fname in Path(results_folder).glob(f'*_merge{suffix}.csv'):\n",
    "    print(f'- Loading {fname}')\n",
    "    name = fname.stem.split('_')[0]\n",
    "    burstph_dict_mergeD2[name] = pd.read_csv(fname, skiprows=1, index_col=(0, 1))\n",
    "    header = fname.read_text().split('\\n')[0]\n",
    "    burstph_dict_mergeD2[name].meta = json.loads(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test roundtrip\n",
    "for name in burstph_dict_merge:\n",
    "    assert (burstph_dict_mergeD[name] == burstph_dict_mergeD2[name]).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate burst data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge FRET bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_FRET_bursts'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix = fret_suffix\n",
    "suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `burst_dict`: key is concentration, values lists of DataFrame\n",
    "burst_dict = defaultdict(list)\n",
    "for fname, row in df_all.iterrows():\n",
    "    burst_fname = Path(results_folder, fname + f'{suffix}.csv')\n",
    "    dx = pd.read_csv(burst_fname, index_col=0)\n",
    "    dx['repeat'] = np.uint8(row['repeat'])\n",
    "    burst_dict[row['name']].append(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['d17', 'd7+d17', 'd7'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burst_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "burst_dict_merge = {}\n",
    "for n in burst_dict:\n",
    "    bursts_merge = pd.concat(burst_dict[n], ignore_index=True)\n",
    "    bursts_merge.index.name = 'burst'\n",
    "    burst_dict_merge[n] = bursts_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['d17', 'd7+d17', 'd7'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burst_dict_merge.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test consistency of burstph_dict_merge and burst_dict_merge\n",
    "for n in burstph_dict_merge:\n",
    "    ph = burstph_dict_merge[n]\n",
    "    bu = burst_dict_merge[n]\n",
    "    assert (ph.groupby('burst')['timestamp'].count() == bu.size_raw).all()\n",
    "\n",
    "    width = (ph.groupby('burst')['timestamp'].max()\n",
    "             - ph.groupby('burst')['timestamp'].min())*50e-9*1e3\n",
    "\n",
    "    assert np.allclose(width, bu.width_ms)\n",
    "    size = bu.nd + bu.na + bu.nda + bu.naa + bu.bg_dd + bu.bg_ad + bu.bg_da + bu.bg_aa\n",
    "    assert np.allclose(size, bu.size_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save FRET burst data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_FRET_bursts'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix = fret_suffix\n",
    "suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Saving file \"d17_merge_FRET_bursts.csv\"\n",
      " - Saving file \"d7+d17_merge_FRET_bursts.csv\"\n",
      " - Saving file \"d7_merge_FRET_bursts.csv\"\n"
     ]
    }
   ],
   "source": [
    "for name, row in df_merge.iterrows():\n",
    "    fname = Path(results_folder, name + f'_merge{suffix}.csv')\n",
    "    print(f' - Saving file \"{fname.name}\"')\n",
    "    burst_dict_merge[name].to_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge D-only bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_Donly_bursts'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix = donly_suffix\n",
    "suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `burst_dict`: key is concentration, values lists of DataFrame\n",
    "burst_dict = defaultdict(list)\n",
    "for fname, row in df_all.iterrows():\n",
    "    burst_fname = Path(results_folder, fname + f'{suffix}.csv')\n",
    "    dx = pd.read_csv(burst_fname, index_col=0)\n",
    "    dx['repeat'] = np.uint8(row['repeat'])\n",
    "    burst_dict[row['name']].append(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "burst_dict_mergeD = {}\n",
    "for n in burst_dict:\n",
    "    bursts_merge = pd.concat(burst_dict[n], ignore_index=True)\n",
    "    bursts_merge.index.name = 'burst'\n",
    "    burst_dict_mergeD[n] = bursts_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test consistency of burstph_dict_merge and burst_dict_merge\n",
    "for n in burstph_dict_mergeD:\n",
    "    ph = burstph_dict_mergeD[n]\n",
    "    bu = burst_dict_mergeD[n]\n",
    "    assert (ph.groupby('burst')['timestamp'].count() == bu.size_raw).all()\n",
    "\n",
    "    width = (ph.groupby('burst')['timestamp'].max()\n",
    "             - ph.groupby('burst')['timestamp'].min())*50e-9*1e3\n",
    "\n",
    "    assert np.allclose(width, bu.width_ms)\n",
    "    size = bu.nd + bu.na + bu.nda + bu.naa + bu.bg_dd + bu.bg_ad + bu.bg_da + bu.bg_aa\n",
    "    assert np.allclose(size, bu.size_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Donly burst data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_Donly_bursts'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix = donly_suffix\n",
    "suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Saving file \"d17_merge_Donly_bursts.csv\"\n",
      " - Saving file \"d7+d17_merge_Donly_bursts.csv\"\n",
      " - Saving file \"d7_merge_Donly_bursts.csv\"\n"
     ]
    }
   ],
   "source": [
    "for name, row in df_merge.iterrows():\n",
    "    fname = Path(results_folder, name + f'_merge{suffix}.csv')\n",
    "    print(f' - Saving file \"{fname.name}\"')\n",
    "    burst_dict_mergeD[name].to_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36-sys)",
   "language": "python",
   "name": "py36-sys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
